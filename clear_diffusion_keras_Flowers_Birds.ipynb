{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mKsXIajqePwJ"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","from datetime import datetime\n","import glob\n","import os\n","import sys\n","import tensorflow_addons as tfa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NArMf93GrDgb"},"outputs":[],"source":["from clear_diffusion_keras.dataset import prepare_dataset\n","from clear_diffusion_keras.architecture import get_augmenter, get_network\n","from clear_diffusion_keras.model import DiffusionModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HiNZwBDUXF_6"},"outputs":[],"source":["def Generate_Iteration(version, dataset_name,\n","                      num_epochs = 40, uncropped_image_size = 64, image_size = 64, batch_size = 64, generated_images=1280,\n","                      kid_image_size = 75  , kid_diffusion_steps = 5,\n","                      prediction_type = \"noise\", loss_type = \"noise\", ema = 0.999, learning_rate = 1e-3, weight_decay = 1e-4,\n","                      schedule_type = \"cosine\", start_log_snr = 2.5, end_log_snr = -7.5,\n","                      noise_embedding_max_frequency = 200.0, noise_embedding_dims = 32, image_embedding_dims = 64, widths = [32, 64, 96, 128], block_depth = 2,\n","  ):\n","\n","  def load_data(dataset, version):\n","    all_files = glob.glob(os.path.join(\"\", f\"./Results_experiments/{dataset}/Version_{version-1}/*.npy\"))\n","    combined_data = np.array([np.load(fname) for fname in all_files])\n","    return combined_data\n","  def generate_images(dataset, version):\n","    Generated_images = model.generate(num_images=64, diffusion_steps=20,  stochasticity=1.0, variance_preserving=True,  num_multisteps=2, second_order_alpha=0.5)\n","    np.save(f\"./Results_experiments/{dataset}/Version_{version}/Generated_{int(round(datetime.now().timestamp()))}.npy\" , Generated_images)\n","\n","  ###\n","  #Model\n","  ###\n","  model = DiffusionModel(\n","      id=version,\n","      augmenter=get_augmenter(\n","          uncropped_image_size=uncropped_image_size, image_size=image_size\n","      ),\n","      network=get_network(\n","          image_size=image_size,\n","          noise_embedding_max_frequency=noise_embedding_max_frequency,\n","          noise_embedding_dims=noise_embedding_dims,\n","          image_embedding_dims=image_embedding_dims,\n","          widths=widths,\n","          block_depth=block_depth,\n","      ),\n","      prediction_type=prediction_type,\n","      loss_type=loss_type,\n","      batch_size=batch_size,\n","      ema=ema,\n","      schedule_type=schedule_type,\n","      start_log_snr=start_log_snr,\n","      end_log_snr=end_log_snr,\n","      kid_image_size=kid_image_size,\n","      kid_diffusion_steps=kid_diffusion_steps,\n","      is_jupyter=True,\n","  )\n","\n","  model.compile(\n","      optimizer=tfa.optimizers.AdamW(\n","          learning_rate=learning_rate, weight_decay=weight_decay\n","      ),\n","      loss=keras.losses.mean_absolute_error,\n","  )\n","\n","  ###\n","  #Load_Dataset\n","  ###\n","  if version < 0:\n","    return print(\"\")\n","  elif version == 1:\n","    datasets_names = {\n","    \"Birds\": \"caltech_birds2011\",\n","    \"Flowers\": \"oxford_flowers102\",\n","    }\n","    train_dataset = prepare_dataset(datasets_names[dataset_name], \"train\", uncropped_image_size, batch_size)\n","    val_dataset = prepare_dataset(\n","        datasets_names[dataset_name], \"validation\", uncropped_image_size, batch_size\n","    )\n","  else:\n","    total_data = load_data(version=version)\n","    train_dataset_gen = total_data[:1024]\n","    val_dataset_gen = total_data[-256:]\n","    train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset_gen)\n","    val_dataset = tf.data.Dataset.from_tensor_slices(val_dataset_gen)\n","\n","  ###\n","  #Train the model\n","  ###\n","  checkpoint_path = \"checkpoints/model_{}\".format(version)\n","  checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","      filepath=checkpoint_path,\n","      save_weights_only=True,\n","      monitor=\"val_kid\",\n","      mode=\"min\",\n","      save_best_only=True,\n","  )\n","  model.augmenter.layers[0].adapt(train_dataset)\n","  model.fit(\n","      train_dataset,\n","      epochs=num_epochs,\n","      validation_data=val_dataset,\n","      callbacks=[\n","          keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images),\n","          checkpoint_callback,\n","      ],\n","  )\n","  model.load_weights(checkpoint_path)\n","  model.evaluate(val_dataset)\n","\n","  ###\n","  #Generate Dataset\n","  ###\n","  for _ in range(generated_images):\n","    generate_images(dataset_name, version=version)\n","    print(f\"Generated: {_}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2S5F7WxA7xAp"},"outputs":[],"source":["for version in range(1, 10):\n","  print(version)\n","  Generate_Iteration(version, 'Birds')\n","  #Generate_Iteration(version, 'Flowers')"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1DsUpHocoaZW5fq08oheUY9CFZmqpvS1T","timestamp":1686045426216},{"file_id":"1pk76MR7DR6Ghzr9DjuHYQtGeOWYUOpEI","timestamp":1681660706923}],"gpuClass":"premium"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":0}